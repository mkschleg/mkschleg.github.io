<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Publications - Matthew Schlegel</title>
<meta name="description" content="Working hard to make machines work harder.">


  <meta name="author" content="Matthew Schlegel">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Matthew Schlegel">
<meta property="og:title" content="Publications">
<meta property="og:url" content="https://mkschleg.github.io/publications/">













<link rel="canonical" href="https://mkschleg.github.io/publications/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "https://mkschleg.github.io/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Matthew Schlegel Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--archive">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Matthew Schlegel
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/publications/" >Publications</a>
            </li><li class="masthead__menu-item">
              <a href="/assets/current-cv.pdf" >CV</a>
            </li><li class="masthead__menu-item">
              <a href="https://www.coffeesideai.com" >Blog</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  

  <div class="archive">
    
      <h1 id="page-title" class="page__title">Publications</h1>
    
    <h3 class="archive_subtitle"> Papers In Progress </h3>

<ol class="bibliography"><li><span id="schlegel2018general"><b>Schlegel, M.</b>, Jacobsen, A., Zaheer, M., Patterson, A., White, A., &amp; White, M. (2018). General Value Function Networks. <i>ArXiv Preprint ArXiv:1807.06763</i>.</span>

<div class="pub-buttons">
    

    <button class="btn btnId btnPub--BibTex" id="b_schlegel2018general-bibtex" style="">BibTeX</button>
    
    

    
    <a href="https://arxiv.org/abs/1807.06763"><button class="btn btnId btnPub--arxiv" style="position:relative;white-space: normal;">Arxiv</button></a>
    
    
    
</div>
    <div class="dropDownBibtex" id="schlegel2018general-bibtex" style="display: none">
    <pre>@article{schlegel2018general,
  title = {General Value Function Networks},
  author = {Schlegel, Matthew and Jacobsen, Andrew and Zaheer, Muhammad and Patterson, Andrew and White, Adam and White, Martha},
  journal = {arXiv preprint arXiv:1807.06763},
  year = {2018},
  arxiv = {https://arxiv.org/abs/1807.06763}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="schlegel2018general-abstract" style="display: none">
    
    </div>
</li></ol>

<h3 class="archive_subtitle"> Published Papers </h3>

<ol class="bibliography"><li><span id="jacobsen2019meta">Jacobsen, A., <b>Schlegel, M.</b>, Linke, C., Degris, T., White, A., &amp; White, M. (2019). Meta-descent for Online, Continual Prediction. In <i>AAAI Conference on Artificial Intelligence</i>.</span>

<div class="pub-buttons">
    
    <button class="btn btnId btnPub--abstract" id="b_jacobsen2019meta-abstract" style="">Abstract</button>
    

    <button class="btn btnId btnPub--BibTex" id="b_jacobsen2019meta-bibtex" style="">BibTeX</button>
    
    

    
    <a href="https://arxiv.org/abs/1907.07751"><button class="btn btnId btnPub--arxiv" style="position:relative;white-space: normal;">Arxiv</button></a>
    
    
    
</div>
    <div class="dropDownBibtex" id="jacobsen2019meta-bibtex" style="display: none">
    <pre>@inproceedings{jacobsen2019meta,
  title = {Meta-descent for Online, Continual Prediction},
  author = {Jacobsen, Andrew and Schlegel, Matthew and Linke, Cameron and Degris, Thomas and White, Adam and White, Martha},
  booktitle = {AAAI Conference on Artificial Intelligence},
  year = {2019},
  arxiv = {https://arxiv.org/abs/1907.07751}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="jacobsen2019meta-abstract" style="display: none">
    This paper investigates different vector step-size adaptation approaches for non-stationary online, continual prediction problems. Vanilla stochastic gradient descent can be considerably improved by scaling the update with a vector of appropriately chosen step-sizes. Many methods, including Ada-Grad, RMSProp, and AMSGrad, keep statistics about the learning process to approximate a second order update—a vector approximation of the inverse Hessian. Another family of approaches use meta-gradient descent to adapt the stepsize parameters to minimize prediction error. These metadescent strategies are promising for non-stationary problems, but have not been as extensively explored as quasi-second order methods. We first derive a general, incremental metadescent algorithm, called AdaGain, designed to be applicable to a much broader range of algorithms, including those with semi-gradient updates or even those with accelerations, such as RMSProp. We provide an empirical comparison of methods from both families. We conclude that methods from both families can perform well, but in non-stationary prediction problems the meta-descent methods exhibit advantages. Our method is particularly robust across several prediction problems, and is competitive with the state-of-the-art method on a large-scale, time-series prediction problem on real data from a mobile robot.
    </div>
</li>
<li><span id="schlegel2019importance"><b>Schlegel, M.</b>, Chung, W., Graves, D., Qian, J., &amp; White, M. (2019). Importance Resampling for Off-policy Prediction. In <i>Advances in Neural Information Processing Systems</i>.</span>

<div class="pub-buttons">
    
    <button class="btn btnId btnPub--abstract" id="b_schlegel2019importance-abstract" style="">Abstract</button>
    

    <button class="btn btnId btnPub--BibTex" id="b_schlegel2019importance-bibtex" style="">BibTeX</button>
    
    

    
    <a href="https://arxiv.org/abs/1906.04328"><button class="btn btnId btnPub--arxiv" style="position:relative;white-space: normal;">Arxiv</button></a>
    
    
    
</div>
    <div class="dropDownBibtex" id="schlegel2019importance-bibtex" style="display: none">
    <pre>@incollection{schlegel2019importance,
  title = {Importance Resampling for Off-policy Prediction},
  author = {Schlegel, Matthew and Chung, Wesley and Graves, Daniel and Qian, Jian and White, Martha},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2019},
  arxiv = {https://arxiv.org/abs/1906.04328}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="schlegel2019importance-abstract" style="display: none">
    Importance sampling (IS) is a common reweighting strategy for off-policy prediction in reinforcement learning. While it is consistent and unbiased, it can result in high variance updates to the weights for the value function. In this work, we explore a resampling strategy as an alternative to reweighting. We propose Importance Resampling (IR) for off-policy prediction, which resamples experience from a replay buffer and applies standard on-policy updates. The approach avoids using importance sampling ratios in the update, instead correcting the distribution before the update. We characterize the bias and consistency of IR, particularly compared to Weighted IS (WIS). We demonstrate in several microworlds that IR has improved sample efficiency and lower variance updates, as compared to IS and several variance-reduced IS strategies, including variants of WIS and V-trace which clips IS ratios. We also provide a demonstration showing IR improves over IS for learning a value function from images in a racing car simulator.
    </div>
</li>
<li><span id="kumaraswamy2018context">Kumaraswamy, R., <b>Schlegel, M.</b>, White, A., &amp; White, M. (2018). Context-dependent upper-confidence bounds for directed exploration. In <i>Advances in Neural Information Processing Systems</i>.</span>

<div class="pub-buttons">
    
    <button class="btn btnId btnPub--abstract" id="b_kumaraswamy2018context-abstract" style="">Abstract</button>
    

    <button class="btn btnId btnPub--BibTex" id="b_kumaraswamy2018context-bibtex" style="">BibTeX</button>
    
    
    <a href="/_publications/kumaraswamy2018context.pdf"><button class="btn btnId btnPub--download" style="position:relative;white-space: normal;">PDF</button></a>
    

    
    
    
</div>
    <div class="dropDownBibtex" id="kumaraswamy2018context-bibtex" style="display: none">
    <pre>@inproceedings{kumaraswamy2018context,
  title = {Context-dependent upper-confidence bounds for directed exploration},
  author = {Kumaraswamy, Raksha and Schlegel, Matthew and White, Adam and White, Martha},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2018}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="kumaraswamy2018context-abstract" style="display: none">
    Directed exploration strategies for reinforcement learning are critical for learning an optimal policy in a minimal number of interactions with the environment. Many algorithms use optimism to direct exploration, either through visitation estimates or upper-confidence bounds, as opposed to data-inefficient strategies like ✏-greedy that use random, undirected exploration. Most data-efficient exploration methods require significant computation, typically relying on a learned model to guide exploration. Least-squares methods have the potential to provide some of the data-efficiency benefits of model-based approaches—because they summarize past interactions—with the computation closer to that of model-free approaches. In this work, we provide a novel, computationally efficient, incremental exploration strategy, leveraging this property of least-squares temporal difference learning (LSTD). We derive upper-confidence bounds on the action-values learned by LSTD, with context-dependent (or state-dependent) noise variance. Such context- dependent noise focuses exploration on a subset of variable states, and allows for reduced exploration in other states. We empirically demonstrate that our algorithm can converge more quickly than other incremental exploration strategies using confidence estimates on action-values.
    </div>
</li>
<li><span id="schlegel2017adapting"><b>Schlegel, M.</b>, Pan, Y., Chen, J., &amp; White, M. (2017). Adapting kernel representations online using submodular maximization. In <i>Proceedings of the 34th International Conference on Machine Learning</i>.</span>

<div class="pub-buttons">
    
    <button class="btn btnId btnPub--abstract" id="b_schlegel2017adapting-abstract" style="">Abstract</button>
    

    <button class="btn btnId btnPub--BibTex" id="b_schlegel2017adapting-bibtex" style="">BibTeX</button>
    
    
    <a href="/_publications/schlegel2017adapting.pdf"><button class="btn btnId btnPub--download" style="position:relative;white-space: normal;">PDF</button></a>
    

    
    
    
</div>
    <div class="dropDownBibtex" id="schlegel2017adapting-bibtex" style="display: none">
    <pre>@inproceedings{schlegel2017adapting,
  title = {Adapting kernel representations online using submodular maximization},
  author = {Schlegel, Matthew and Pan, Yangchen and Chen, Jiecao and White, Martha},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year = {2017}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="schlegel2017adapting-abstract" style="display: none">
    Kernel representations provide a nonlinear repre- sentation, through similarities to prototypes, but require only simple linear learning algorithms given those prototypes. In a continual learning setting, with a constant stream of observations, it is critical to have an efficient mechanism for sub-selecting prototypes amongst observations. In this work, we develop an approximately submodular criterion for this setting, and an efficient online greedy submodular maximization algorithm for optimizing the criterion. We extend streaming submodular maximization algorithms to continual learning, by removing the need for multiple passes which is infeasible and instead introducing the idea of coverage time. We propose a general block-diagonal approximation for the greedy update with our criterion, that enables updates linear in the number of prototypes. We empirically demonstrate the effectiveness of this approximation, in terms of approximation quality, significant runtime improvements, and effective prediction performance.
    </div>
</li></ol>

<h3 class="archive_subtitle"> Other Publications </h3>

<ol class="bibliography"><li><span id="schlegel2018baseline"><b>Schlegel, M.</b>, White, A., &amp; White, M. (2018). A Baseline of Discovery for General Value Function Networks under Partial Observability. <i>NeurIPS Workshop on Reinforcement Learning under Partial Observability</i>.</span>

<div class="pub-buttons">
    

    <button class="btn btnId btnPub--BibTex" id="b_schlegel2018baseline-bibtex" style="">BibTeX</button>
    
    
    <a href="/_publications/schlegel2018baseline.pdf"><button class="btn btnId btnPub--download" style="position:relative;white-space: normal;">PDF</button></a>
    

    
    
    
</div>
    <div class="dropDownBibtex" id="schlegel2018baseline-bibtex" style="display: none">
    <pre>@workshop{schlegel2018baseline,
  title = {A Baseline of Discovery for General Value Function Networks under Partial Observability},
  author = {Schlegel, Matthew and White, Adam and White, Martha},
  year = {2018},
  booktitle = {NeurIPS Workshop on Reinforcement Learning under Partial Observability}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="schlegel2018baseline-abstract" style="display: none">
    
    </div>
</li>
<li><span id="schlegel2017stable"><b>Schlegel, M.</b>, White, A., &amp; White, M. (2017). Stable predictive representations with general value functions for continual learning. <i>NeurIPS Workshop on Continual Learning and Deep Networks</i>.</span>

<div class="pub-buttons">
    

    <button class="btn btnId btnPub--BibTex" id="b_schlegel2017stable-bibtex" style="">BibTeX</button>
    
    
    <a href="/_publications/schlegel2017stable.pdf"><button class="btn btnId btnPub--download" style="position:relative;white-space: normal;">PDF</button></a>
    

    
    
    
</div>
    <div class="dropDownBibtex" id="schlegel2017stable-bibtex" style="display: none">
    <pre>@workshop{schlegel2017stable,
  title = {Stable predictive representations with general value functions for continual learning},
  author = {Schlegel, Matthew and White, Adam and White, Martha},
  year = {2017},
  booktitle = {NeurIPS Workshop on Continual Learning and Deep Networks}
}
</pre>
    </div>
    
    <div class="dropDownAbstract" id="schlegel2017stable-abstract" style="display: none">
    
    </div>
</li></ol>


  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Matthew Schlegel. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>










  </body>
</html>
