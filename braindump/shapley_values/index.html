<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.102.1" />
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=Page%28/braindump/shapley_values.md%29%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  

  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/shapley_values/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/shapley_values/">
  <meta property="og:title" content="Shapley Values | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-08-30T13:56:43-06:00">
  <meta property="article:modified_time" content="2022-08-30T13:56:43-06:00">
  

  <title>Shapley Values | Matthew Schlegel</title>

  

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; PhD student at Amii, RLAI and UofA; Works on how machines perceive their world.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/shapley_values/">Shapley Values</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2022-08-30 13:56:43 -0600 MDT" itemprop="datePublished dateModified">
      Aug 30, 2022
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <p>\( \newcommand{\states}{\mathcal{S}}
\newcommand{\actions}{\mathcal{A}}
\newcommand{\observations}{\mathcal{O}}
\newcommand{\rewards}{\mathcal{R}}
\newcommand{\traces}{\mathbf{e}}
\newcommand{\transition}{P}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\expected}{\mathbb{E}}
\newcommand{\by}{\times}
\newcommand{\partialderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\defineq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\defeq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\eye}{\Imat}
\newcommand{\hadamard}{\odot}
\newcommand{\trans}{\top}
\newcommand{\inv}{{-1}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\avec}{\mathbf{a}}
\newcommand{\bvec}{\mathbf{b}}
\newcommand{\cvec}{\mathbf{c}}
\newcommand{\dvec}{\mathbf{d}}
\newcommand{\evec}{\mathbf{e}}
\newcommand{\gvec}{\mathbf{g}}
\newcommand{\hvec}{\mathbf{h}}
\newcommand{\lvec}{\mathbf{l}}
\newcommand{\mvec}{\mathbf{m}}
\newcommand{\nvec}{\mathbf{n}}
\newcommand{\pvec}{\mathbf{p}}
\newcommand{\qvec}{\mathbf{q}}
\newcommand{\rvec}{\mathbf{r}}
\newcommand{\svec}{\mathbf{s}}
\newcommand{\uvec}{\mathbf{u}}
\newcommand{\vvec}{\mathbf{v}}
\newcommand{\wvec}{\mathbf{w}}
\newcommand{\xvec}{\mathbf{x}}
\newcommand{\yvec}{\mathbf{y}}
\newcommand{\zvec}{\mathbf{z}}
\newcommand{\Amat}{\mathbf{A}}
\newcommand{\Bmat}{\mathbf{B}}
\newcommand{\Cmat}{\mathbf{C}}
\newcommand{\Dmat}{\mathbf{D}}
\newcommand{\Emat}{\mathbf{E}}
\newcommand{\Fmat}{\mathbf{F}}
\newcommand{\Imat}{\mathbf{I}}
\newcommand{\Pmat}{\mathbf{P}}
\newcommand{\Umat}{\mathbf{U}}
\newcommand{\Vmat}{\mathbf{V}}
\newcommand{\Wmat}{\mathbf{W}}
\newcommand{\Xmat}{\mathbf{X}}
\newcommand{\Qmat}{\mathbf{Q}}
\newcommand{\thetavec}{\boldsymbol{\theta}}
\newcommand{\phivec}{\boldsymbol{\phi}}
\newcommand{\muvec}{\boldsymbol{\mu}}
\newcommand{\sigmavec}{\boldsymbol{\sigma}}
\newcommand{\jacobian}{\mathbf{J}}
\newcommand{\ind}{\perp!!!!\perp}
\)</p>
<h2 id="what-are-shapley-values"><span class="org-todo done DONE">DONE</span> What are shapley values?</h2>
<p>Shapley values are a solution for a coalitional game. Specifically, they assign a value or payout according to the a player&rsquo;s contribution to the overall teams win/objective/yada.</p>
<p>For a linear function:</p>
<p>\[\hat{f}(x) = \eta + \sum_{i=1}^N \beta_i x_i\]</p>
<p>Where \(x_i\) are the features and \(\beta_i\) are the weights of the linear function. The contribution of the $j$-th feature from instance \(\mathbf{x}\in\mathcal{X}\) is</p>
<p>\[\phi_j(\mathbf{x}) = \beta_j (\mathbf{x}_j - \expected[X_j])\].</p>
<p>for more general functions, we can&rsquo;t rule out interactions between different features in the function and thus must effectively marginalize over these interactions.</p>
<pre><code>\begin{align\*}
</code></pre>
<p>\phi_j(val) &amp;= \sum_{S\subset\{1, \ldots, p\}/\{j\}} \frac{|S|! (p - |S| - 1)!}{p!} (val(S\cup\{j\}) - val(S)) \\
val_x(S) &amp;= \int \hat{f}(\mathbf{x}) d\mathbb{P}_{X \notin S} - \expected[\hat{f}(\mathbf{x})]
\end{align*}</p>
<h3 id="7c43a8">(<a href="#citeproc_bib_item_4">Molnar, n.d.</a>)</h3>
<h3 id="no-item-data-lundberg">(NO_ITEM_DATA:lundberg)</h3>
<h3 id="7260c4">(<a href="#citeproc_bib_item_6">Singal, Michailidis, and Ng 2021</a>)</h3>
<h3 id="54614a">(<a href="#citeproc_bib_item_2">Heskes et al. 2020</a>)</h3>
<h3 id="b588ec">(<a href="#citeproc_bib_item_3">Ma and Tourani 2020</a>)</h3>
<p>Prove that blindly using shapley values to identify/interpret/explain a model is not appropriate. Specifically, they provde two counter examples where they show the important features aren&rsquo;t guaranteed to have the largest shapley value (as compared to other features), and that the sum of SVs also don&rsquo;t correspond directly with the intuitive assumption.</p>
<h2 id="how-do-we-estimate-shapley-values"><span class="org-todo done DONE">DONE</span> How do we estimate Shapley Values?</h2>
<h3 id="5d9820">(<a href="#citeproc_bib_item_8">Strumbelj and Kononenko 2014</a>)</h3>
<p>A monte carlo method which approximates the shapley value as</p>
<p>\[\phi_i (x) = \frac{1}{M} \sum_{m=1}^M \hat{f}(x_{+j}) - \hat{f}(x_{-j}) \]</p>
<p>where \(x_{+j} = (x_1, \ldtos, x_{j-1}, x_j, z_{j+1}, \ldots)\) and \(x_{-j} = (x_1, \ldtos, x_{j-1}, z_j, z_{j+1}, \ldots)\). \(z\) is another instance sampled from the dataset. The order of features is randomly ordered.</p>
<h3 id="0884c8">(<a href="#citeproc_bib_item_7">Song, Nelson, and Staum 2016</a>)</h3>
<p>The Shapley effect results in the same value as the Shapley value, but gives a different direction for optimization. To measure the global sensitivity of a function according to a set of features you can calculate the value:</p>
<p>\[ v_i = \sum_{\mathcal{J}\subset\mathcal{k}\\{i\}} \frac{(k - |\mathcal{J}| - 1)! |\mathcal{J}|!}{k!} (c(P_i(\pi) \cum {i}) - c(P_i(\pi)))\]</p>
<p>There are two cost/value functions \(c\) one can consider when calculating the global sensitivity of a function wrt to a set of features. The cost measures the variance of Y caused by the uncertainty of the inputs in \(\mathcal{J}\). The first (considered by (<a href="#citeproc_bib_item_5">Owen 2014</a>)) is</p>
<p>\[\tilde{c}(\mathcal{J}) = \text{Var}[\text{E}[Y | \mathbf{X}_\mathcal{J}]].\]</p>
<p>Another choice is</p>
<p>\[c(\mathcal{J}) = \text{E}[\text{Var}[Y|\mathbf{-\mathcal{J}}]]\]</p>
<p>where \(\mathbf{X}{-\mathcal{J}} = \mathbf{X}_{K\\J}\).</p>
<p>While both costs result in the same values \(v_i\), the resulting estimators are different.</p>
<p>The question is how does this effect the estimator in both bias and sample efficiency.</p>
<h2 id="independent-shapley-values">Independent Shapley Values</h2>
<p>ISV is the style of shapley value introduced above. The empty coalition is the background input.</p>
<h2 id="conditional-shapley-values"><span class="org-todo todo TODO">TODO</span> Conditional Shapley Values</h2>
<h2 id="asymetric-shapley-values"><span class="org-todo todo TODO">TODO</span> Asymetric Shapley Values</h2>
<p>Asymetric shapley values may be what we want in the bandit case. The question is does knowing the ordering of ASVs give us the minimal intervention set?
(<a href="#citeproc_bib_item_1">Frye et al. 2021</a>)</p>
<h2 id="recursive-shapley-values">Recursive Shapley Values</h2>
<p>(<a href="#citeproc_bib_item_6">Singal, Michailidis, and Ng 2021</a>)</p>
<h2 id="references">References</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Frye, Christopher, Damien de Mijolla, Tom Begley, Laurence Cowton, Megan Stanley, and Ilya Feige. 2021. “Shapley Explainability on the Data Manifold.” <i>arXiv:2006.01272 [Cs, Stat]</i>. <a href="https://arxiv.org/abs/2006.01272">https://arxiv.org/abs/2006.01272</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Heskes, Tom, Evi Sijben, Ioan Gabriel Bucur, and Tom Claassen. 2020. “Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models.” <i>arXiv:2011.01625 [Cs]</i>. <a href="https://arxiv.org/abs/2011.01625">https://arxiv.org/abs/2011.01625</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Ma, Sisi, and Roshan Tourani. 2020. “Predictive and Causal Implications of Using Shapley Value for Model Interpretation.” In <i>Proceedings of the 2020 KDD Workshop on Causal Discovery</i>. PMLR.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Molnar, Christoph. n.d. <i>9.5 Shapley Values | Interpretable Machine Learning</i>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>Owen, Art B. 2014. “Sobol’ Indices and Shapley Value.” <i>SIAM/ASA Journal on Uncertainty Quantification</i>. Society for Industrial and Applied Mathematics.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>Singal, Raghav, George Michailidis, and Hoiyi Ng. 2021. “Flow-Based Attribution in Graphical Models: A Recursive Shapley Approach.” SSRN Scholarly Paper. Rochester, NY: Social Science Research Network.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>Song, Eunhye, Barry L. Nelson, and Jeremy Staum. 2016. “Shapley Effects for Global Sensitivity Analysis: Theory and Computation.” <i>SIAM/ASA Journal on Uncertainty Quantification</i>. Society for Industrial and Applied Mathematics.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Strumbelj, Erik, and Igor Kononenko. 2014. “Explaining Prediction Models and Individual Predictions with Feature Contributions.” <i>Knowledge and Information Systems</i>.</div>
  <div class="csl-entry">NO_ITEM_DATA:lundberg</div>
</div>
    </div>

    
    

    

    
    

    

    

    

  </div>
</article>

                                


   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   




			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright © 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

