<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.144.1">
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=/Users/matt/Documents/Professional/website/content/braindump/jaderberg2017_reinforcement_learning_with_unsupervised_auxiliary_tasks.md%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/jaderberg2017reinforcement/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/jaderberg2017reinforcement/">
  <meta property="og:title" content="jaderberg2017reinforcement: Reinforcement Learning with Unsupervised Auxiliary Tasks | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2025-02-21T10:28:01-07:00">
  
  <meta property="article:modified_time" content="2025-02-21T10:28:01-07:00">
  

  <title>jaderberg2017reinforcement: Reinforcement Learning with Unsupervised Auxiliary Tasks | Matthew Schlegel</title>

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; Focused on RL and ML to improve the world; Research Scientist with a penchant for good software and alliteration.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/jaderberg2017reinforcement/">jaderberg2017reinforcement: Reinforcement Learning with Unsupervised Auxiliary Tasks</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2025-02-21 10:28:01 -0700 MST" itemprop="datePublished dateModified">
      Feb 21, 2025
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <dl>
<dt>tags</dt>
<dd><a href="/braindump/reinforcement_learning/">Reinforcement Learning</a>, <a href="/braindump/deep_reinforcement_learning/">Deep Reinforcement Learning</a>, <a href="/braindump/auxiliary_tasks/">Auxiliary Tasks</a></dd>
<dt>source</dt>
<dd><a href="https://arxiv.org/pdf/1611.05397.pdf">https://arxiv.org/pdf/1611.05397.pdf</a></dd>
</dl>
<p><strong>Unreal Agent:</strong></p>
<ul>
<li>Base agent is a CNN-LSTM ANN trained on-policy using A3C (<a href="#citeproc_bib_item_1">Mnih et al. 2016</a>) using a replay buffer of observations, rewards, and actions.</li>
<li>Pixel control: auxiliary policies \(Q^\text{aux}\) are trained to maximize change in pixel intensity of different regions.</li>
<li>Reward prediction: given three recent frames, the network must predict the reward that will be obtained in the next unobserved timestep.</li>
<li>Value Function Replay: further training of the value function using the agent network.</li>
</ul>
<p>The overall architecture jointly optimizes all of its objectives.</p>
<h2 id="auxiliary-control-tasks">Auxiliary Control Tasks</h2>
<p>These are defined as an additional pseudo-reward function in the environment. This is similar to a control <a href="/braindump/general_value_functions/">GVF</a>. In this paper, they use Q-Learning as described by (<a href="#citeproc_bib_item_1">Mnih et al. 2016</a>) for learning the auxiliary control tasks. They use two types of rewards:</p>
<ul>
<li><strong>Pixel Changes</strong>: Learn a policy for maximally changing the pixels in each cell of an \(n \times n\) non-overlapping grid placed over the input image.</li>
<li><strong>Network Features</strong>: maximially activating each of the units in a specific hidden layer.</li>
</ul>
<h2 id="auxiliary-reward-task">Auxiliary Reward Task</h2>
<p>In addition to the control tasks, they also propose to add a reward prediction task. This is to predict the one-step reward at the end of a short sequence of states (for the LSTM).</p>
<h2 id="value-function-replay">Value function replay</h2>
<p><a href="/braindump/experience_replay/">Experience Replay</a> is used not only for the usual case, but also in value function replay. This effectively resamples recent historical sequences from behaviour policy distributions and performing extra value function regression in addition to the on-policy updates in <a href="/braindump/jaderberg2017/">A3C</a>. The <a href="/braindump/experience_replay/">ER buffer</a> is also used in the auxiliary control tasks described above.</p>
<h2 id="results">Results</h2>
<p>Across all domains tested they show an improvement over baseline <a href="/braindump/jaderberg2017/">A3C</a>.</p>
<p>They test across several domains:</p>
<ul>
<li><a href="/braindump/atari/">Atari</a></li>
<li><a href="/braindump/deepmind_lab/">DeepMind Lab</a></li>
</ul>
<p>They use a set of other baselines which are all ablation studies on the UNREAL architecture.</p>
<h2 id="references">References</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Mnih, Volodymyr, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 2016. “Asynchronous Methods for Deep Reinforcement Learning.” In <i>International Conference on Machine Learning</i>, 1928–37.</div>
</div>

    </div>

    
    

    

    
    

    

    

    

    
    




   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   




    

  </div>
</article>

			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright © 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

