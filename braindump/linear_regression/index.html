<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.144.1">
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=/Users/matt/Documents/Professional/PrevProfessional/website/content/braindump/linear_regression.md%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/linear_regression/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/linear_regression/">
  <meta property="og:title" content="Linear Regression | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-11-10T16:45:22-07:00">
  
  <meta property="article:modified_time" content="2022-11-10T16:45:22-07:00">
  

  <title>Linear Regression | Matthew Schlegel</title>

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; Focused on RL and ML to improve the world; Research Scientist with a penchant for good software and alliteration.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/linear_regression/">Linear Regression</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2022-11-10 16:45:22 -0700 MST" itemprop="datePublished dateModified">
      Nov 10, 2022
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <p>\( \newcommand{\states}{\mathcal{S}}
\newcommand{\actions}{\mathcal{A}}
\newcommand{\observations}{\mathcal{O}}
\newcommand{\rewards}{\mathcal{R}}
\newcommand{\traces}{\mathbf{e}}
\newcommand{\transition}{P}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\complexs}{\mathbb{C}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\numfield}{\mathbb{F}}
\newcommand{\expected}{\mathbb{E}}
\newcommand{\var}{\mathbb{V}}
\newcommand{\by}{\times}
\newcommand{\partialderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\defineq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\defeq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\eye}{\Imat}
\newcommand{\hadamard}{\odot}
\newcommand{\trans}{\top}
\newcommand{\inv}{{-1}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\avec}{\mathbf{a}}
\newcommand{\bvec}{\mathbf{b}}
\newcommand{\cvec}{\mathbf{c}}
\newcommand{\dvec}{\mathbf{d}}
\newcommand{\evec}{\mathbf{e}}
\newcommand{\fvec}{\mathbf{f}}
\newcommand{\gvec}{\mathbf{g}}
\newcommand{\hvec}{\mathbf{h}}
\newcommand{\ivec}{\mathbf{i}}
\newcommand{\jvec}{\mathbf{j}}
\newcommand{\kvec}{\mathbf{k}}
\newcommand{\lvec}{\mathbf{l}}
\newcommand{\mvec}{\mathbf{m}}
\newcommand{\nvec}{\mathbf{n}}
\newcommand{\ovec}{\mathbf{o}}
\newcommand{\pvec}{\mathbf{p}}
\newcommand{\qvec}{\mathbf{q}}
\newcommand{\rvec}{\mathbf{r}}
\newcommand{\svec}{\mathbf{s}}
\newcommand{\tvec}{\mathbf{t}}
\newcommand{\uvec}{\mathbf{u}}
\newcommand{\vvec}{\mathbf{v}}
\newcommand{\wvec}{\mathbf{w}}
\newcommand{\xvec}{\mathbf{x}}
\newcommand{\yvec}{\mathbf{y}}
\newcommand{\zvec}{\mathbf{z}}
\newcommand{\Amat}{\mathbf{A}}
\newcommand{\Bmat}{\mathbf{B}}
\newcommand{\Cmat}{\mathbf{C}}
\newcommand{\Dmat}{\mathbf{D}}
\newcommand{\Emat}{\mathbf{E}}
\newcommand{\Fmat}{\mathbf{F}}
\newcommand{\Gmat}{\mathbf{G}}
\newcommand{\Hmat}{\mathbf{H}}
\newcommand{\Imat}{\mathbf{I}}
\newcommand{\Jmat}{\mathbf{J}}
\newcommand{\Kmat}{\mathbf{K}}
\newcommand{\Lmat}{\mathbf{L}}
\newcommand{\Mmat}{\mathbf{M}}
\newcommand{\Nmat}{\mathbf{N}}
\newcommand{\Omat}{\mathbf{O}}
\newcommand{\Pmat}{\mathbf{P}}
\newcommand{\Qmat}{\mathbf{Q}}
\newcommand{\Rmat}{\mathbf{R}}
\newcommand{\Smat}{\mathbf{S}}
\newcommand{\Tmat}{\mathbf{T}}
\newcommand{\Umat}{\mathbf{U}}
\newcommand{\Vmat}{\mathbf{V}}
\newcommand{\Wmat}{\mathbf{W}}
\newcommand{\Xmat}{\mathbf{X}}
\newcommand{\Ymat}{\mathbf{Y}}
\newcommand{\Zmat}{\mathbf{Z}}
\newcommand{\Sigmamat}{\boldsymbol{\Sigma}}
\newcommand{\identity}{\Imat}
\newcommand{\epsilonvec}{\boldsymbol{\epsilon}}
\newcommand{\thetavec}{\boldsymbol{\theta}}
\newcommand{\phivec}{\boldsymbol{\phi}}
\newcommand{\muvec}{\boldsymbol{\mu}}
\newcommand{\sigmavec}{\boldsymbol{\sigma}}
\newcommand{\jacobian}{\mathbf{J}}
\newcommand{\ind}{\perp!!!!\perp}
\newcommand{\bigoh}{\text{O}}
\)</p>
<dl>
<dt>tags</dt>
<dd><a href="/braindump/machine_learning/">Machine Learning</a>, <a href="/braindump/statistics/">Statistics</a></dd>
</dl>
<p>Linear regression is the simplest form of regression and is used to minimize the mean squared error (MSE). More specifically, we model the labels as a linear function with error
\[
\yvec = \Xmat \wvec + \boldsymbol{\varepsilon}
\]
where,</p>
<p>\[\begin{align*}
\yvec &amp;= \begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix} \\
\Xmat &amp;= \begin{bmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2p} \\
1 &amp; x_{31} &amp; x_{32} &amp; \ldots &amp; x_{3p} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{np} \\
\end{bmatrix} \\
\boldsymbol{\varepsilon} &amp;= \begin{bmatrix}
\varepsilon_1 \\
\varepsilon_2 \\
\vdots \\
\varepsilon_n
\end{bmatrix},
\wvec = \begin{bmatrix}
w_1 \\
w_2 \\
\vdots \\
w_n
\end{bmatrix}
\end{align*}\]</p>
<aside title="Ordering of Features">
<p>Make note of the ordering of the features and the added bias bit in the features. The bias bit allows the linear equation to be affine (i.e. change the intersection of the decision plane). Each row is now an example, although we usually assume examples to be column vectors. This can be easily re-written, but it is a choice made likely because `c` (and many linear algebra packages) is row-major.</p>
</aside>
<p>We should also note that there are several assumptions that are taken on when using linear regression:</p>
<ol>
<li><strong>Independence</strong>: This is such a common assumption throughout statistics. This means all the data in our design matrix are sampled from the underlying distribution independently.</li>
<li><strong>Normal Distribution</strong>: The data is distributed according to \(y_i \sim \mathcal{N}(\xvec_i^\trans \wvec, \sigma^2)\)</li>
<li>(<strong>homoscedasticity</strong>) where the variance of the distribution \(\sigma^2\) is independent of the features or targets</li>
<li>and the expectation of the target has a <strong>linear relationship</strong> with the features \(\expected[y_i] = \xvec_i^\trans \wvec\).</li>
<li>No or very little <strong>multicolinearity</strong>: This means there is no exact relationship amongst &ldquo;exploratory&rdquo; variables, or the columns of the design matrix are not very correlated.</li>
</ol>
<h2 id="ordinary-least-squares">Ordinary Least Squares</h2>
<p>The most commonly used technique is that of linear least squares. This procedure finds the global minima of the objective function</p>
<p>\begin{align*}
L(D, \wvec) &amp;= \lVert \Xmat\wvec - \yvec \rVert_2^2 \\
&amp;= (\Xmat\wvec - \yvec)^\trans (\Xmat\wvec - \yvec) \\
&amp;= \yvec^\trans\yvec - \yvec^\trans\Xmat\wvec - \wvec^\trans\Xmat^\trans\yvec + \wvec^\trans\Xmat^\trans\Xmat\wvec
\end{align*}</p>
<p>Now taking the derivative and setting to zero we can find the global minimum at
\[\wvec = (\Xmat^\trans \Xmat)^\inv \Xmat^\trans \yvec.\]</p>
<p>With the condition that \(\Xmat^\trans\Xmat\) is not singular (i.e. the determinant is \(0\)).</p>
<h3 id="maximum-likelihood-estimation--maximum-likelihood-estimation-dot-md--derivation"><a href="/braindump/maximum_likelihood_estimation/">Maximum Likelihood Estimation</a> Derivation</h3>
<p>A natural question is &ldquo;why should we minimize the MSE?&rdquo; Where does this loss function come from? The Ordinary Least Squares solution is an excellent example of the application of <a href="/braindump/maximum_likelihood_estimation/">Maximum Likelihood Estimation</a> with a gaussian distribution!</p>
<p>More exactly, lets start with the following distribution assumption on the targets
\[y_i \sim \mathcal{N}(x_i^\trans w, \sigma^2).\]</p>
<p>We want to maximize the likelihood of our target variable</p>
<p>\[\prob[Y | X] &amp;= \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{\lVert Y - X^\trans \wvec \rVert^2}{2\sigma^2}}\]</p>

    </div>

    
    

    

    
    

    

    

    

    
    




   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   



  <div class="bl-section">
    <h4>Links to this note:</h4>
    <div class="backlinks">
      <ul>
       
          <li><a href="/braindump/interview_review_material/">Interview Review Material</a></li>
       
     </ul>
    </div>
  </div>


    

  </div>
</article>

			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright Â© 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

