<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.144.1">
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=/Users/matt/Documents/Professional/PrevProfessional/website/content/braindump/mohamed2019_monte_carlo_gradient_estimation_in_machine_learning.md%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/mohamed2019monte/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/mohamed2019monte/">
  <meta property="og:title" content="mohamed2019monte: Monte Carlo Gradient Estimation in Machine Learning | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-11-08T14:21:02-07:00">
  
  <meta property="article:modified_time" content="2022-11-08T14:21:02-07:00">
  

  <title>mohamed2019monte: Monte Carlo Gradient Estimation in Machine Learning | Matthew Schlegel</title>

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; Focused on RL and ML to improve the world; Research Scientist with a penchant for good software and alliteration.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/mohamed2019monte/">mohamed2019monte: Monte Carlo Gradient Estimation in Machine Learning</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2022-11-08 14:21:02 -0700 MST" itemprop="datePublished dateModified">
      Nov 8, 2022
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <p>\( \newcommand{\states}{\mathcal{S}}
\newcommand{\actions}{\mathcal{A}}
\newcommand{\observations}{\mathcal{O}}
\newcommand{\rewards}{\mathcal{R}}
\newcommand{\traces}{\mathbf{e}}
\newcommand{\transition}{P}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\complexs}{\mathbb{C}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\numfield}{\mathbb{F}}
\newcommand{\expected}{\mathbb{E}}
\newcommand{\var}{\mathbb{V}}
\newcommand{\by}{\times}
\newcommand{\partialderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\defineq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\defeq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\eye}{\Imat}
\newcommand{\hadamard}{\odot}
\newcommand{\trans}{\top}
\newcommand{\inv}{{-1}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\avec}{\mathbf{a}}
\newcommand{\bvec}{\mathbf{b}}
\newcommand{\cvec}{\mathbf{c}}
\newcommand{\dvec}{\mathbf{d}}
\newcommand{\evec}{\mathbf{e}}
\newcommand{\fvec}{\mathbf{f}}
\newcommand{\gvec}{\mathbf{g}}
\newcommand{\hvec}{\mathbf{h}}
\newcommand{\ivec}{\mathbf{i}}
\newcommand{\jvec}{\mathbf{j}}
\newcommand{\kvec}{\mathbf{k}}
\newcommand{\lvec}{\mathbf{l}}
\newcommand{\mvec}{\mathbf{m}}
\newcommand{\nvec}{\mathbf{n}}
\newcommand{\ovec}{\mathbf{o}}
\newcommand{\pvec}{\mathbf{p}}
\newcommand{\qvec}{\mathbf{q}}
\newcommand{\rvec}{\mathbf{r}}
\newcommand{\svec}{\mathbf{s}}
\newcommand{\tvec}{\mathbf{t}}
\newcommand{\uvec}{\mathbf{u}}
\newcommand{\vvec}{\mathbf{v}}
\newcommand{\wvec}{\mathbf{w}}
\newcommand{\xvec}{\mathbf{x}}
\newcommand{\yvec}{\mathbf{y}}
\newcommand{\zvec}{\mathbf{z}}
\newcommand{\Amat}{\mathbf{A}}
\newcommand{\Bmat}{\mathbf{B}}
\newcommand{\Cmat}{\mathbf{C}}
\newcommand{\Dmat}{\mathbf{D}}
\newcommand{\Emat}{\mathbf{E}}
\newcommand{\Fmat}{\mathbf{F}}
\newcommand{\Gmat}{\mathbf{G}}
\newcommand{\Hmat}{\mathbf{H}}
\newcommand{\Imat}{\mathbf{I}}
\newcommand{\Jmat}{\mathbf{J}}
\newcommand{\Kmat}{\mathbf{K}}
\newcommand{\Lmat}{\mathbf{L}}
\newcommand{\Mmat}{\mathbf{M}}
\newcommand{\Nmat}{\mathbf{N}}
\newcommand{\Omat}{\mathbf{O}}
\newcommand{\Pmat}{\mathbf{P}}
\newcommand{\Qmat}{\mathbf{Q}}
\newcommand{\Rmat}{\mathbf{R}}
\newcommand{\Smat}{\mathbf{S}}
\newcommand{\Tmat}{\mathbf{T}}
\newcommand{\Umat}{\mathbf{U}}
\newcommand{\Vmat}{\mathbf{V}}
\newcommand{\Wmat}{\mathbf{W}}
\newcommand{\Xmat}{\mathbf{X}}
\newcommand{\Ymat}{\mathbf{Y}}
\newcommand{\Zmat}{\mathbf{Z}}
\newcommand{\Sigmamat}{\boldsymbol{\Sigma}}
\newcommand{\identity}{\Imat}
\newcommand{\epsilonvec}{\boldsymbol{\epsilon}}
\newcommand{\thetavec}{\boldsymbol{\theta}}
\newcommand{\phivec}{\boldsymbol{\phi}}
\newcommand{\muvec}{\boldsymbol{\mu}}
\newcommand{\sigmavec}{\boldsymbol{\sigma}}
\newcommand{\jacobian}{\mathbf{J}}
\newcommand{\ind}{\perp!!!!\perp}
\newcommand{\bigoh}{\text{O}}
\)</p>
<dl>
<dt>tags</dt>
<dd><a href="/braindump/machine_learning/">Machine Learning</a></dd>
<dt>source</dt>
<dd><a href="https://arxiv.org/abs/1906.10652">https://arxiv.org/abs/1906.10652</a></dd>
<dt>authors</dt>
<dd>Mohamed, S., Rosca, M., Figurnov, M., &amp; Mnih, A.</dd>
<dt>year</dt>
<dd>2019</dd>
</dl>
<p>This paper is a broad survey of Monte Carlo gradient estimation techniques for Machine Learning. My interest in this topic is mostly from an off-policy prediction standpoint, but is a really nice general survey of these techniques.</p>
<p>The main goal is to compute a general probabilistic object \(\mathcal{F}\):</p>
<p>\begin{equation}
\mathcal{F}(\boldsymbol{\theta}) :=\int p(\mathbf{x} ; \boldsymbol{\theta}) f(\mathbf{x} ; \boldsymbol{\phi}) d \mathbf{x}=\mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}[f(\mathbf{x} ; \boldsymbol{\phi})]
\end{equation}</p>
<p>This is a <em>mean-value analysis</em> in which a function \(f\) of an input variable \(\mathbf{x}\) with parameters \(\mathbf{\phi}\) is evaluated on average with respect to an input distribution \(p(\mathbf{x};\mathbf{\theta})\) with distributional parameters \(\mathbf{\theta}\).</p>
<ul>
<li>\(f\) is the <em>cost</em></li>
<li>\(p(\mathbf{x};\mathbf{\theta})\) is the <em>measure</em></li>
</ul>
<p>We need to learn the distributional parameters \(\theta\) so we take the gradient</p>
<p>\begin{equation}
\label{eq:mohamed2019:grad_mva}
\boldsymbol{\eta} :=\nabla_{\boldsymbol{\theta}} \mathcal{F}(\boldsymbol{\theta})=\nabla_{\boldsymbol{\theta}} \mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}[f(\mathbf{x} ; \boldsymbol{\phi})]
\end{equation}</p>
<p>Which is the <em>sensitivity analysis</em> of \(\mathcal{F}\) (the gradient of the expectation with respect to the distributional parameters). This gradient problem is difficult in general!</p>
<ul>
<li>Can&rsquo;t evaluate the expectation in closed form</li>
<li>the integrals over \(\mathbf{x}\) are typically high-dimensional making quadrature ineffective</li>
<li>The gradient can be wrt high dimensional distribution parameters \(\mathbf{\theta}\)</li>
<li>And often \(\mathcal{F}\) is not differentiable.</li>
</ul>
<p>We need efficient, accurate and parallelisable solutions that minimize the number of evaluations of the cost.</p>
<p>This will be organized into several sections</p>
<ul>
<li>General principles</li>
<li>Estimators</li>
<li>Variance Reduction</li>
<li>Conclusions, Related work, and future directions.</li>
</ul>
<h2 id="general-principles-of-monte-carlo-methods">General Principles of Monte Carlo Methods</h2>
<h3 id="monte-carlo-estimators">Monte Carlo Estimators</h3>
<p>Consider the equation <a href="eq:mohamed2019:mean_value_analysis_problem">eq:mohamed2019:mean_value_analysis_problem</a>. This integral is often not in known in a closed form. , and not amenable to evaluation using numerical methods!</p>
<p>Instead we can estimate the integral using the monte-carlo method:</p>
<p>\begin{equation}
\overline{\mathcal{F}}_{N}=\frac{1}{N} \sum_{n=1}^{N} f\left(\hat{\mathbf{x}}^{(n)}\right), \text { where } \hat{\mathbf{x}}^{(n)} \sim p(\mathbf{x} ; \boldsymbol{\theta}) \text { for } n=1, \ldots, N
\end{equation}</p>
<p>The quantity \(\overline{\mathcal{F}}\) is a random variable, since it depends on a specific set of random variates (samples) \(\{\hat{\mathbf{x}}^{(1)} \ldots \hat{\mathbf{x}}^{(n)}\}\). We can repeat this many times by constructing multiple sets of the random samples.</p>
<p>There are four properties we will consider with a monte carlo estimator:</p>
<ul>
<li>
<p><strong>Consitency</strong>: Does the estimator \(\overline{\mathcal{F}}_{N}\) converge to the true value of the integral as \(N\) (or the number of samples) increases.</p>
</li>
<li>
<p><strong>Unbiasedness</strong>: If we repeat the estimation process many times, we should find that the estimate is centered on the actual value of the integral on average. For example, the Monte Carlo estimator:</p>
<p>\[ \mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}\left[\overline{\mathcal{F}}_{N}\right]=\mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}\left[\frac{1}{N} \sum_{n=1}^{N} f\left(\mathbf{x}^{(n)}\right)\right]=\frac{1}{N} \sum_{n=1}^{N} \mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}\left[f\left(\mathbf{x}^{(n)}\right)\right]=\mathbb{E}_{p(\mathbf{x} ; \boldsymbol{\theta})}[f(\mathbf{x})] \].</p>
</li>
<li>
<p><strong>Minimum Variance</strong>: We will always prefer the estimators with lower variance (given all else is the same).</p>
<ol>
<li>The resulting gradient estimates are more accurate.</li>
<li>When the gradient is used for stochastic optimisation, low-variance gradients make learning more efficient (allowing for larger learning rates to be used and reducing the total number of steps to convergence).</li>
</ol>
</li>
<li>
<p><strong>Computational efficiency</strong>: We will always prefer an estimator that is computationally efficient (allow the expectation to be computed using the fewest number of samples).</p>
</li>
</ul>
<h3 id="stochastic-optimization">Stochastic Optimization</h3>
<p>The gradient found in equation <a href="eq:mohamed2019:mean_value_analysis_problem">eq:mohamed2019:mean_value_analysis_problem</a> supports two computational tasks</p>
<ol>
<li>Explanation:
This gradient is an useful tool to <em>explain</em> the behavior of the probabilistic systm.</li>
<li>Optimization:
The key quantity need for optimization of the distributional parameters \(\mathbf{\theta}\).</li>
</ol>
<p>You can consider stochastic optimisation as a loop using a simulation phase and an optimisation phase. This process is a stocastic system because the system or the environment has elements of randomness. Because of this, we will call the system for an <em>estimate</em> of the gradient or Hessian rather than the <em>true</em> gradient or Hessian.</p>
<p>If the optimisation phase is use with stochastic approximation (e.g. stochastic gradient descent) then this can be thought of as a double-stochastic optimization.</p>
<h3 id="central-role-of-gradient-estimation">Central role of gradient estimation</h3>
<p>To make the problem more concrete, here are 5 areas in which these estimates are critical.</p>
<!--list-separator-->
<ul>
<li>
<p>Variational Inference</p>
<p>General method for approximating complex and unknown distributions by the closest distribution within a tractable family.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Reinforcement Learning</p>
<p>Model-free policy search, where we learn a policy&mdash;a distribution over actions&mdash;that on average maximises the accumulation of long-term rewards. You can then learn a policy using policy gradient methods with the gradient:</p>
<p>\[\boldsymbol{\eta}=\nabla_{\boldsymbol{\theta}} \mathbb{E}_{p(\boldsymbol{\tau} ; \boldsymbol{\theta})}\left[\sum_{t=0}^{T} \gamma^{t} r\left(\mathbf{s}_{t}, \mathbf{a}_{t}\right)\right]\]</p>
<p>which again has the form of equation <a href="eq:mohamed2019:mean_value_analysis_problem">eq:mohamed2019:mean_value_analysis_problem</a>.</p>
<ul>
<li><strong>cost:</strong> is the return over the trajectory, which is a weighted sum of rewards obtained at each time step.</li>
<li><strong>measure</strong>: is the joint distribution over states and actions \(p(\mathbf{\tau};\mathbf{\theta})\prod_{t=0}^{T} p\left(\mathbf{s}_{t+1} | \mathbf{s}_{t}, \mathbf{a}_{t}\right) p\left(\mathbf{a}_{t} | \mathbf{s}_{t} ; \boldsymbol{\theta}\right)\) which is the product of a state transition distribution and the policy distribution.</li>
</ul>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Sensitivity Analysis</p>
<p>Deals with the study of problems of the form <a href="eq:mohamed2019:grad_mva">eq:mohamed2019:grad_mva</a>, and asks what the sensitivity (or gradient) of an expectation is to its input parameters.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Discrete Event Systems and Queuing Theory</p>
<p>This is the study of waiting systems, or queues.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Experimental Design</p>
<p>Here we are interested in finding the best designs&ndash;the inputs or settings to a possibly unknown system&ndash;that result in outputs that are optimal wrt some utility or score.</p>
</li>
</ul>
<h2 id="intuitive-analysis-of-gradient-estimators">Intuitive Analysis of Gradient Estimators</h2>
<p>The structure of the analysis problem <a href="eq:mohamed2019:grad_mva">eq:mohamed2019:grad_mva</a> directly suggests two possible computations for the gradients:</p>
<ul>
<li><strong>Derivatives of Measure</strong>: The gradient can be computed by differentiation of the measure \(p(\mathbf{x};\boldsymbol{\theta})\).
<ul>
<li>Examples: score function estimator <a href="sec:mohamed2019:score_func_est">sec:mohamed2019:score_func_est</a>, measure-valued gradient <a href="sec:mohamed2019:meas_valued_grads">sec:mohamed2019:meas_valued_grads</a></li>
</ul>
</li>
<li><strong>Derivatives of Path</strong>: The gradient can be computed by differentiation of the cost \(f(\mathbf{x})\), which encodes the pathway from parameters \(\boldsymbol{\theta}\), through the random variable \(\mathbf{x}\), to the cost value.
<ul>
<li>Examples: Pathwise gradient <a href="sec:mohamed2019:pathwise_grad_est">sec:mohamed2019:pathwise_grad_est</a>, harmonic gradient estimators, and Malliavin-weighted estimators.</li>
</ul>
</li>
</ul>
<p>The paper then goes into some intuitive exploration of a simple problem
\[
\eta=\nabla_{\theta} \int \mathcal{N}\left(x | \mu, \sigma^{2}\right) f(x ; k) d x ; \quad \theta \in\{\mu, \sigma\} ; \quad f \in\left\{(x-k)^{2}, \exp \left(-k x^{2}\right), \cos (k x)\right\}
\].</p>
<p>In all they find that a universal ordering is difficult to determine (and in many cases impossible). They suggest three criteria on which to judge the estimators:</p>
<ul>
<li>computational cost,</li>
<li>implications on the use of differentiable and non-differentiable cost functions,</li>
<li>the change in behaviour as the cost itself changes,</li>
<li>and the availability of variance reduction techniques.</li>
</ul>
<h2 id="estimators">Estimators <code>[0/3]</code></h2>
<p>This section details three estimators mentioned above.</p>
<h3 id="score-function-gradient-estimators">Score Function Gradient Estimators</h3>
<h3 id="pathwise-gradient-estimators">Pathwise Gradient Estimators</h3>
<h3 id="measure-valued-gradients">Measure-valued Gradients</h3>

    </div>

    
    

    

    
    

    

    

    

    
    




   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   




    

  </div>
</article>

			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright Â© 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

