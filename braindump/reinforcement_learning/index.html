<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.144.1">
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=/Users/matt/Documents/Professional/PrevProfessional/website/content/braindump/reinforcement_learning.md%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/reinforcement_learning/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/reinforcement_learning/">
  <meta property="og:title" content="Reinforcement Learning | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2023-07-07T13:15:33-06:00">
  
  <meta property="article:modified_time" content="2023-07-07T13:15:33-06:00">
  

  <title>Reinforcement Learning | Matthew Schlegel</title>

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; Focused on RL and ML to improve the world; Research Scientist with a penchant for good software and alliteration.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/reinforcement_learning/">Reinforcement Learning</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2023-07-07 13:15:33 -0600 MDT" itemprop="datePublished dateModified">
      Jul 7, 2023
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <h2 id="questions">Questions</h2>
<h2 id="topics">Topics</h2>
<h3 id="off-policy-reinforcement-learning--off-policy-reinforcement-learning-dot-md"><a href="/braindump/off_policy_reinforcement_learning/">Off-policy Reinforcement Learning</a></h3>
<h3 id="deep-reinforcement-learning--deep-reinforcement-learning-dot-md"><a href="/braindump/deep_reinforcement_learning/">Deep Reinforcement Learning</a></h3>
<h3 id="pretraining-for-reinforcement-learning--pretraining-for-reinforcement-learning-dot-md"><a href="/braindump/pretraining_for_reinforcement_learning/">Pretraining for Reinforcement Learning</a></h3>
<h2 id="recommended-reading">Recommended Reading</h2>
<h3 id="reinforcement-learning-an-introduction"><a href="http://www.incompleteideas.net/book/the-book-2nd.html">Reinforcement Learning: An Introduction</a></h3>
<h3 id="deep-reinforcement-learning--deep-reinforcement-learning-dot-md"><a href="/braindump/deep_reinforcement_learning/">Deep Reinforcement Learning</a></h3>
<h3 id="d41d8c"></h3>

    </div>

    
    


<div class="post-tags">
  <h4> Tags: </h4>
  
  <a href="/tags/Reinforcement-Learning">Reinforcement-Learning</a>
  
</div>



    

    
    

    

    

    

    
    




   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   
      
   

   
      
   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   
      
   

   
      
   

   

   

   

   
      
   

   

   

   

   

   

   
      
   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   
      
   

   
      
   

   

   
      
   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   
      
   

   

   
      
   

   
      
   

   

   

   

   

   

   

   

   
      
   

   

   
      
   

   
      
   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   
      
   

   

   

   
      
   

   
      
   

   

   

   

   

   
      
   

   

   

   
      
   

   

   
      
   

   

   
      
   

   
      
   

   

   

   
      
   

   

   
      
   

   

   
      
   

   
      
   

   
      
   

   
      
   

   

   

   
      
   

   

   

   
      
   

   

   
      
   

   
      
   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   
      
   

   
      
   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   



  <div class="bl-section">
    <h4>Links to this note:</h4>
    <div class="backlinks">
      <ul>
       
          <li><a href="/braindump/current_learning_objectives/">Current Learning Objectives</a></li>
       
          <li><a href="/braindump/inbox/">StudyPlan</a></li>
       
          <li><a href="/braindump/schwarzer2021pretraining/">schwarzer2021pretraining: Pretraining Representations for Data-Efficient Reinforcement Learning</a></li>
       
          <li><a href="/braindump/artificial_intelligence/">Artificial Intelligence</a></li>
       
          <li><a href="/braindump/actor_critic/">Actor Critic</a></li>
       
          <li><a href="/braindump/chatgpt/">ChatGPT</a></li>
       
          <li><a href="/braindump/incentive_salience/">Incentive Salience</a></li>
       
          <li><a href="/braindump/reinforcement_learning_in_the_brain/">Reinforcement Learning in the Brain</a></li>
       
          <li><a href="/braindump/reproducibility_in_science/">Reproducibility in Science</a></li>
       
          <li><a href="/braindump/predictive_processing/">Predictive Processing</a></li>
       
          <li><a href="/braindump/deep_reinforcement_learning/">Deep Reinforcement Learning</a></li>
       
          <li><a href="/braindump/policy/">Policy</a></li>
       
          <li><a href="/braindump/off_policy_reinforcement_learning/">Off-policy Reinforcement Learning</a></li>
       
          <li><a href="/braindump/henderson2018deep/">henderson2018deep: Deep Reinforcement Learning That Matters</a></li>
       
          <li><a href="/braindump/colombo2014deep/">colombo2014deep: Deep and beautiful. The reward prediction error hypothesis of dopamine</a></li>
       
          <li><a href="/braindump/niv2009reinforcement/">niv2009reinforcement: Reinforcement learning in the brain</a></li>
       
          <li><a href="/braindump/dopamine/">Dopamine</a></li>
       
          <li><a href="/braindump/dopaminergic_neurons/">Dopaminergic Neurons</a></li>
       
          <li><a href="/braindump/bellman_equation/">Bellman Equation</a></li>
       
          <li><a href="/braindump/atari/">Atari</a></li>
       
          <li><a href="/braindump/badia2020agent57/">badia2020agent57: Agent57: Outperforming the Atari Human Benchmark</a></li>
       
          <li><a href="/braindump/barreto2018successor/">barreto2018successor: Successor Features for Transfer in Reinforcement Learning</a></li>
       
          <li><a href="/braindump/dayan1993improving/">dayan1993improving: Improving Generalization for Temporal Difference Learning: The Successor Representation</a></li>
       
          <li><a href="/braindump/jaderberg2017reinforcement/">jaderberg2017reinforcement: Reinforcement Learning with Unsupervised Auxiliary Tasks</a></li>
       
          <li><a href="/braindump/kearney2019making/">kearney2019making: Making Meaning: Semiotics Within Predictive Knowledge Architectures</a></li>
       
          <li><a href="/braindump/kostas2019asynchronous/">kostas2019asynchronous: Asynchronous Coagent Networks: Stochastic Networks for Reinforcement Learning without Backpropagation or a Clock</a></li>
       
          <li><a href="/braindump/machado2018revisiting/">machado2018revisiting: Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents</a></li>
       
          <li><a href="/braindump/model_based_rl/">Model-based RL</a></li>
       
          <li><a href="/braindump/mountain_car/">Mountain Car</a></li>
       
          <li><a href="/braindump/reinforcement_learning_an_introduction/">Reinforcement Learning: An Introduction</a></li>
       
          <li><a href="/braindump/causality_for_machine_learning/">scholkopf2019causality: Causality for Machine Learning</a></li>
       
          <li><a href="/braindump/subramanian2020approximate/">subramanian2020approximate: Approximate information state for approximate planning and reinforcement learning in partially observed systems</a></li>
       
          <li><a href="/braindump/sutton2011horde/">sutton2011horde: Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction</a></li>
       
          <li><a href="/braindump/temporal_difference_learning/">Temporal Difference Learning</a></li>
       
          <li><a href="/braindump/veeriah2019discovery/">veeriah2019discovery: Discovery of Useful Questions as Auxiliary Tasks</a></li>
       
          <li><a href="/braindump/wang2017learning/">wang2017learning: Learning to reinforcement learn</a></li>
       
          <li><a href="/braindump/white2015developing/">white2015developing: Developing a predictive approach to knowledge</a></li>
       
          <li><a href="/braindump/auxiliary_tasks/">Auxiliary Tasks</a></li>
       
          <li><a href="/braindump/white2017/">white2017unifying: Unifying Task Specification in Reinforcement Learning</a></li>
       
          <li><a href="/braindump/vanhasselt2015learning/">vanhasselt2015learning: Learning to Predict Independent of Span</a></li>
       
          <li><a href="/braindump/value_function/">Value Function</a></li>
       
          <li><a href="/braindump/types_of_learning/">Types of Learning</a></li>
       
          <li><a href="/braindump/rich_sutton/">Rich Sutton</a></li>
       
          <li><a href="/braindump/reward/">Reward</a></li>
       
          <li><a href="/braindump/jaderberg2017/">mnih2016asynchronous: Asynchronous Methods for Deep Reinforcement Learning</a></li>
       
          <li><a href="/braindump/markov_decisions_process/">Markov Decisions Process</a></li>
       
          <li><a href="/braindump/liu2018breaking/">liu2018breaking: Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation</a></li>
       
          <li><a href="/braindump/sutton1988learning/">sutton1988learning: Learning to predict by the methods of temporal differences</a></li>
       
          <li><a href="/braindump/experience_replay/">Experience Replay</a></li>
       
          <li><a href="/braindump/deepmind_lab/">DeepMind Lab</a></li>
       
          <li><a href="/braindump/behavior_suite/">Behavior-Suite</a></li>
       
     </ul>
    </div>
  </div>


    

  </div>
</article>

			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright © 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

