<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="robots" content="noindex">
  <meta name="googlebot" content="noindex">
  
  
  <meta name="generator" content="Hugo 0.144.1">
  <meta name="author" content="Matthew Schlegel">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.pageState=/Users/matt/Documents/Professional/website/content/braindump/niv2009reinforcement_reinforcement_learning_in_the_brain.md%29">
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/header.css">
  
  <link rel="stylesheet" href="/css/img.css">
  
  <link rel="stylesheet" href="/css/braindump.css">
  
  <link rel="stylesheet" href="/css/post.css">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://mkschleg.github.io/braindump/niv2009reinforcement/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@mattschleg">
  <meta property="twitter:creator" content="@mattschleg">
  
  <meta property="og:site_name" content="Matthew Schlegel">
  <meta property="og:url" content="https://mkschleg.github.io/braindump/niv2009reinforcement/">
  <meta property="og:title" content="niv2009reinforcement: Reinforcement learning in the brain | Matthew Schlegel">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2025-02-21T10:28:34-07:00">
  
  <meta property="article:modified_time" content="2025-02-21T10:28:34-07:00">
  

  <title>niv2009reinforcement: Reinforcement learning in the brain | Matthew Schlegel</title>

  
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']], 
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head>
<body>

<style type="text/css">
  
 
  
 
</style>

<div class="masthead-hero"></div>


<div id="main" role="main">
  <div class="sidebar sticky" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <div class="author-avatar">
    <a href="/">
      
      <img src="/img/me.jpg" alt="Matthew Schlegel" itemprop="image">
      
    </a>
  </div>
  <div class="author-content">
    <h3 class="author-name" itemprop="name">Matthew Schlegel</h3>
    <p class="author-bio" itemprop="description">Lover of Espresso; Focused on RL and ML to improve the world; Research Scientist with a penchant for good software and alliteration.</p>
  </div>
  <div class="author-urls-wrapper">
    <ul class="author-urls social-icons" aria-hidden="true">
      <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
        <span itemprop="name">Edmonton, Alberta</span>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//linkedin.com/in/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-linkedin"></i>
          LinkedIn
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//twitter.com/mattschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-twitter"></i>
          Twitter
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href="//github.com/mkschleg" target="_blank" rel="noopener noreferrer">
          <i class="fa fa-github"></i>
          Github
        </a>
      </li>
      
    </ul>
    <ul class="author-urls social-icons" aria-hidden="true" style="margin-top:30px;">
      
      <li>
        <a itemprop="sameAs" href=/tags >
          <i class="fa fa-tag"></i>
          Tags
        </a>
      </li>
      
      <li>
        <a itemprop="sameAs" href=/collections >
          <i class="fa fa-folder"></i>
          Collections
        </a>
      </li>
      
    </ul>
  </div>
</div>

  <article class="page">
		<div class="page_container">
			<section class="page_content">
				<div class="navbar-hero">
  <nav>
    
    
    <a class="hover" href="/">Home</a>
    
    
    <a class="hover" href="/about">About</a>
    
    
    <a class="hover" href="/CV.pdf">CV</a>
    
    
    <a class="hover" href="/publications">Publications</a>
    
    
    <a class="hover" href="/code">Code</a>
    
    
    <a class="hover" href=/braindump> BrainDump </a>
    
  </nav>
</div>

				<article class="post" itemscope itemtype="http://schema.org/Article">
  <div class="post-container">
    <h1 itemprop="name"><a href="https://mkschleg.github.io/braindump/niv2009reinforcement/">niv2009reinforcement: Reinforcement learning in the brain</a></h1>

    
      

<div class="post-metadata">

  <span class="post-date">
    
    <time datetime="2025-02-21 10:28:34 -0700 MST" itemprop="datePublished dateModified">
      Feb 21, 2025
    </time>
  </span>

  

</div>

    

    <div class="post-style" itemprop="articleBody">
      
      <p>\( \newcommand{\states}{\mathcal{S}}
\newcommand{\actions}{\mathcal{A}}
\newcommand{\observations}{\mathcal{O}}
\newcommand{\rewards}{\mathcal{R}}
\newcommand{\traces}{\mathbf{e}}
\newcommand{\transition}{P}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\complexs}{\mathbb{C}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\numfield}{\mathbb{F}}
\newcommand{\expected}{\mathbb{E}}
\newcommand{\var}{\mathbb{V}}
\newcommand{\by}{\times}
\newcommand{\partialderiv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\defineq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\defeq}{\stackrel{{\tiny\mbox{def}}}{=}}
\newcommand{\eye}{\Imat}
\newcommand{\hadamard}{\odot}
\newcommand{\trans}{\top}
\newcommand{\inv}{{-1}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\avec}{\mathbf{a}}
\newcommand{\bvec}{\mathbf{b}}
\newcommand{\cvec}{\mathbf{c}}
\newcommand{\dvec}{\mathbf{d}}
\newcommand{\evec}{\mathbf{e}}
\newcommand{\fvec}{\mathbf{f}}
\newcommand{\gvec}{\mathbf{g}}
\newcommand{\hvec}{\mathbf{h}}
\newcommand{\ivec}{\mathbf{i}}
\newcommand{\jvec}{\mathbf{j}}
\newcommand{\kvec}{\mathbf{k}}
\newcommand{\lvec}{\mathbf{l}}
\newcommand{\mvec}{\mathbf{m}}
\newcommand{\nvec}{\mathbf{n}}
\newcommand{\ovec}{\mathbf{o}}
\newcommand{\pvec}{\mathbf{p}}
\newcommand{\qvec}{\mathbf{q}}
\newcommand{\rvec}{\mathbf{r}}
\newcommand{\svec}{\mathbf{s}}
\newcommand{\tvec}{\mathbf{t}}
\newcommand{\uvec}{\mathbf{u}}
\newcommand{\vvec}{\mathbf{v}}
\newcommand{\wvec}{\mathbf{w}}
\newcommand{\xvec}{\mathbf{x}}
\newcommand{\yvec}{\mathbf{y}}
\newcommand{\zvec}{\mathbf{z}}
\newcommand{\Amat}{\mathbf{A}}
\newcommand{\Bmat}{\mathbf{B}}
\newcommand{\Cmat}{\mathbf{C}}
\newcommand{\Dmat}{\mathbf{D}}
\newcommand{\Emat}{\mathbf{E}}
\newcommand{\Fmat}{\mathbf{F}}
\newcommand{\Gmat}{\mathbf{G}}
\newcommand{\Hmat}{\mathbf{H}}
\newcommand{\Imat}{\mathbf{I}}
\newcommand{\Jmat}{\mathbf{J}}
\newcommand{\Kmat}{\mathbf{K}}
\newcommand{\Lmat}{\mathbf{L}}
\newcommand{\Mmat}{\mathbf{M}}
\newcommand{\Nmat}{\mathbf{N}}
\newcommand{\Omat}{\mathbf{O}}
\newcommand{\Pmat}{\mathbf{P}}
\newcommand{\Qmat}{\mathbf{Q}}
\newcommand{\Rmat}{\mathbf{R}}
\newcommand{\Smat}{\mathbf{S}}
\newcommand{\Tmat}{\mathbf{T}}
\newcommand{\Umat}{\mathbf{U}}
\newcommand{\Vmat}{\mathbf{V}}
\newcommand{\Wmat}{\mathbf{W}}
\newcommand{\Xmat}{\mathbf{X}}
\newcommand{\Ymat}{\mathbf{Y}}
\newcommand{\Zmat}{\mathbf{Z}}
\newcommand{\Sigmamat}{\boldsymbol{\Sigma}}
\newcommand{\identity}{\Imat}
\newcommand{\epsilonvec}{\boldsymbol{\epsilon}}
\newcommand{\thetavec}{\boldsymbol{\theta}}
\newcommand{\phivec}{\boldsymbol{\phi}}
\newcommand{\muvec}{\boldsymbol{\mu}}
\newcommand{\sigmavec}{\boldsymbol{\sigma}}
\newcommand{\jacobian}{\mathbf{J}}
\newcommand{\ind}{\perp!!!!\perp}
\newcommand{\bigoh}{\text{O}}
\)</p>
<dl>
<dt>tags</dt>
<dd><a href="/braindump/brain/">Brain</a>, <a href="/braindump/reinforcement_learning_in_the_brain/">Reinforcement Learning in the Brain</a>, <a href="/braindump/reinforcement_learning/">Reinforcement Learning</a></dd>
<dt>source</dt>
<dd><a href="https://www.sciencedirect.com/science/article/pii/S0022249608001181?casa_token=lgOWwyFDA5YAAAAA:2a5tx84lb8-GRkVh_puGph5Wx6yccKjuq7_wf9HOw_2RguIRXOe2RG13vtsrCNRs4EP-8JrvCGxL">link</a></dd>
<dt>authors</dt>
<dd>Niv, Y.</dd>
<dt>year</dt>
<dd>2009</dd>
</dl>
<h2 id="quotes">Quotes</h2>
<blockquote>
<p>Most notably, much evidence suggest that the neuromodulator dopamine provides basal ganglia target structures with phasic signals that convey a reward prediction error that can influence learning and action selection, particularly in stimulus-driven habitual instrumental behavior.</p></blockquote>
<!--quoteend-->
<blockquote>
<p>That is, RL models (1) generate predictions regarding the molar and molecular forms of optimal behavior. (2) suggests a means by which optimal prediction and action selection can be achieved, and (3) expose explicitly the computations that must be realized in the service of these.</p></blockquote>
<!--quoteend-->
<blockquote>
<p>Specifically, extracellular recordings in behaving animals and functional imaging of human decision-making have revealed in the brain the existence of a key RL signal, the temporal difference reward prediction error. In this review we will focus on these links between the theory of reinforcement learning and its implementation in animal and human neural processing.</p></blockquote>
<!--quoteend-->
<blockquote>
<p>Rescorla and Wagner postulated that the associative strength of each of the conditional stimuli \(V(CS_i)\) will change according to
\[
V_{new}(CS_i) = V_{old}(CS_i) + \eta \left[ \lambda_{US} - \sum_i V_{old}(CS_i) \right].
\]
In this <em>error correcting</em> learning rule, learning is driven by the discrepancy between what was predicted (\(\sum_i V(CS_i)\) where \(i\) indexes all the CSs present in the trial) and what actually happened (\(\lambda_{US}\) whose magnitude is related to the worth of the unconditional stimulus, and which quantifies the maximal associative strength that the unconditional stimulus can support.)</p></blockquote>
<!--quoteend-->
<blockquote>
<p>At the basis of the Rescorla-Wagner model are two important (and innovative) assumptions or hypotheses: (1) learning happens only when events are not predicted, and (2) predictions due to different stimuli are summed to form the total prediction in a trial.</p></blockquote>
<p>Issues with the Rescorla-Wagner model:</p>
<ol>
<li>By treating the conditional and unconditional stimuli as qualitatively different, it does not extend to the important phenomenon of second order conditioning. If stimulus B predicts an affective outcome and stimulus A predicts stimulus B, then stimulus A also gains reward predictive value in <strong>second order conditioning</strong>.</li>
<li>The basic unit of learning is a conditioning <em>trial</em> as a discrete temporal object. Not only does this impose an experimenter-oriented parsing of otherwise continuous events, but it also fails to account for the sensitivity of conditioning to the different temporal relations between the conditional and the unconditional stimuli <em>within</em> a trial.</li>
</ol>
<p>(<a href="#citeproc_bib_item_7">Werbos 1977</a>) in his &ldquo;heuristic dynamic programming methods&rdquo;, and later (<a href="#citeproc_bib_item_1">Barto, Sutton, and Watkins 1989</a>) suggested that in a &ldquo;model-free&rdquo; case in which we can not assume knowledge of the dynamics of the environment, the environment itself can supply this information stochastically and incrementally.</p>
<blockquote>
<p>Contrary to the &ldquo;dopamine equals reward&rdquo; hypothesis, the disappearance of the dopaminergic response to reward delivery did not accompany extinction, but rather it followed acquisition of the conditioning relationship&mdash;as the cells ceased to respond to reward the monkeys began showing conditioned responses of anticipatory licking and arm movements to the reward-predictive stimulus.</p></blockquote>
<!--quoteend-->
<blockquote>
<p>The close correspondence between the phasic dopaminergic firing patterns and the characteristics of a temporal difference prediction error led Montague et al. (1996) to sugges the <em>reward prediction error hypothesis</em> of dopamine. Whithin this theoretical framework, it was immediately clear why dopamine is necessary for reward mediated learning in the basal ganglia.</p></blockquote>
<p>While the reward prediction error hypothesis is precise, there are many open questions and challenges.</p>
<ol>
<li><a href="/braindump/dopaminergic_neurons/">Dopaminergic Neurons</a> do not seem to be involved in the signaling or predictions errors for aversive outcomes (<a href="#citeproc_bib_item_3">Mirenowicz and Schultz 1996</a>), (<a href="#citeproc_bib_item_5">Tobler, Dickinson, and Schultz 2003</a>), (<a href="#citeproc_bib_item_6">Ungless, Magill, and Bolam 2004</a>).
<ul>
<li><a href="/braindump/dopaminergic_neurons/">Dopaminergic Neurons</a> do signal negative prediction errors due to the absence of appetitive outcomes.</li>
</ul>
</li>
<li><a href="/braindump/dopaminergic_neurons/">Dopaminergic Neurons</a> fire to stimuli not clearly related to reward prediction, specifically in the presence of novel stimuli (<a href="#citeproc_bib_item_4">Schultz 1998</a>), although they are not (yet) predictive of any outcome, aversive or appetitive.
<ul>
<li>(<a href="#citeproc_bib_item_2">Kakade and Dayan 2002</a>) addressed this possibility directly, and suggests that the novelty responses can function as &rsquo;novelty bonuses&rsquo;&mdash;quantities that are added to other available reward (\(r^{new}_t = r_t + \text{novelty}(S_t))\) and enhance exploration of novel stimuli.</li>
<li>This has been confirmed by (<a href="#citeproc_bib_item_8">Wittmann et al. 2008</a>) using fMRI readings.</li>
</ul>
</li>
<li>Another challenge is how hierarchical structure plays a role in learning behaviors. A quintessential example of this is the everyday task of making coffee, which comprises several high-level &lsquo;modules&rsquo; such as &lsquo;grind beans&rsquo;, &lsquo;pour water&rsquo;, &lsquo;add sugar&rsquo;, each of which, in turn, comprises many lower-level motor actions.</li>
</ol>
<h2 id="references">References</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Barto, A. G., R. S. Sutton, and C. J. C. H. Watkins. 1989. “Sequential Decision Problems and Neural Networks.” In <i>Advances in Neural Information Processing Systems</i>. Vol. 2. Morgan-Kaufmann.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Kakade, Sham, and Peter Dayan. 2002. “Dopamine: Generalization and Bonuses.” <i>Neural Networks</i> 15 (4): 549–59. doi:<a href="https://doi.org/10.1016/S0893-6080(02)00048-5">10.1016/S0893-6080(02)00048-5</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Mirenowicz, Jacques, and Wolfram Schultz. 1996. “Preferential Activation of Midbrain Dopamine Neurons by Appetitive Rather than Aversive Stimuli.” <i>Nature</i> 379 (6564, 6564). Nature Publishing Group: 449–51. doi:<a href="https://doi.org/10.1038/379449a0">10.1038/379449a0</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Schultz, Wolfram. 1998. “Predictive Reward Signal of Dopamine Neurons.” <i>Journal of Neurophysiology</i> 80 (1). American Physiological Society: 1–27. doi:<a href="https://doi.org/10.1152/jn.1998.80.1.1">10.1152/jn.1998.80.1.1</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>Tobler, Philippe N., Anthony Dickinson, and Wolfram Schultz. 2003. “Coding of Predicted Reward Omission by Dopamine Neurons in a Conditioned Inhibition Paradigm.” <i>Journal of Neuroscience</i> 23 (32). Society for Neuroscience: 10402–10. doi:<a href="https://doi.org/10.1523/JNEUROSCI.23-32-10402.2003">10.1523/JNEUROSCI.23-32-10402.2003</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>Ungless, Mark A., Peter J. Magill, and J. Paul Bolam. 2004. “Uniform Inhibition of Dopamine Neurons in the Ventral Tegmental Area by Aversive Stimuli.” <i>Science</i> 303 (5666). American Association for the Advancement of Science: 2040–42. doi:<a href="https://doi.org/10.1126/science.1093360">10.1126/science.1093360</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>Werbos, P. 1977. “Advanced Forecasting Methods for Global Crisis Warning and Models of Intelligence.” <i>General System Yearbook</i>, 25–38.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Wittmann, Bianca C., Nathaniel D. Daw, Ben Seymour, and Raymond J. Dolan. 2008. “Striatal Activity Underlies Novelty-Based Choice in Humans.” <i>Neuron</i> 58 (6): 967–73. doi:<a href="https://doi.org/10.1016/j.neuron.2008.04.027">10.1016/j.neuron.2008.04.027</a>.</div>
</div>

    </div>

    
    

    

    
    

    

    

    

    
    




   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   
      
   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   



  <div class="bl-section">
    <h4>Links to this note:</h4>
    <div class="backlinks">
      <ul>
       
          <li><a href="/braindump/current_learning_objectives/">Current Learning Objectives</a></li>
       
          <li><a href="/braindump/inbox/">StudyPlan</a></li>
       
     </ul>
    </div>
  </div>


    

  </div>
</article>

			</section>
		</div>
	</article>
</div> 


<div class="page_footer">
	<p>Copyright © 2020 Matthew Schlegel. All Rights Reserved. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>

